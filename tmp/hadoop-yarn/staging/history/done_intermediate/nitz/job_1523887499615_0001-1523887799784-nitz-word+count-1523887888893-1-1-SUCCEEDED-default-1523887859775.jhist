Avro-Binary
{"type":"record","name":"Event","namespace":"org.apache.hadoop.mapreduce.jobhistory","fields":[{"name":"type","type":{"type":"enum","name":"EventType","symbols":["JOB_SUBMITTED","JOB_INITED","JOB_FINISHED","JOB_PRIORITY_CHANGED","JOB_STATUS_CHANGED","JOB_QUEUE_CHANGED","JOB_FAILED","JOB_KILLED","JOB_ERROR","JOB_INFO_CHANGED","TASK_STARTED","TASK_FINISHED","TASK_FAILED","TASK_UPDATED","NORMALIZED_RESOURCE","MAP_ATTEMPT_STARTED","MAP_ATTEMPT_FINISHED","MAP_ATTEMPT_FAILED","MAP_ATTEMPT_KILLED","REDUCE_ATTEMPT_STARTED","REDUCE_ATTEMPT_FINISHED","REDUCE_ATTEMPT_FAILED","REDUCE_ATTEMPT_KILLED","SETUP_ATTEMPT_STARTED","SETUP_ATTEMPT_FINISHED","SETUP_ATTEMPT_FAILED","SETUP_ATTEMPT_KILLED","CLEANUP_ATTEMPT_STARTED","CLEANUP_ATTEMPT_FINISHED","CLEANUP_ATTEMPT_FAILED","CLEANUP_ATTEMPT_KILLED","AM_STARTED"]}},{"name":"event","type":[{"type":"record","name":"JobFinished","fields":[{"name":"jobid","type":"string"},{"name":"finishTime","type":"long"},{"name":"finishedMaps","type":"int"},{"name":"finishedReduces","type":"int"},{"name":"failedMaps","type":"int"},{"name":"failedReduces","type":"int"},{"name":"totalCounters","type":{"type":"record","name":"JhCounters","fields":[{"name":"name","type":"string"},{"name":"groups","type":{"type":"array","items":{"type":"record","name":"JhCounterGroup","fields":[{"name":"name","type":"string"},{"name":"displayName","type":"string"},{"name":"counts","type":{"type":"array","items":{"type":"record","name":"JhCounter","fields":[{"name":"name","type":"string"},{"name":"displayName","type":"string"},{"name":"value","type":"long"}]}}}]}}}]}},{"name":"mapCounters","type":"JhCounters"},{"name":"reduceCounters","type":"JhCounters"},{"name":"killedMaps","type":"int","default":-1},{"name":"killedReduces","type":"int","default":-1}]},{"type":"record","name":"JobInfoChange","fields":[{"name":"jobid","type":"string"},{"name":"submitTime","type":"long"},{"name":"launchTime","type":"long"}]},{"type":"record","name":"JobInited","fields":[{"name":"jobid","type":"string"},{"name":"launchTime","type":"long"},{"name":"totalMaps","type":"int"},{"name":"totalReduces","type":"int"},{"name":"jobStatus","type":"string"},{"name":"uberized","type":"boolean"}]},{"type":"record","name":"AMStarted","fields":[{"name":"applicationAttemptId","type":"string"},{"name":"startTime","type":"long"},{"name":"containerId","type":"string"},{"name":"nodeManagerHost","type":"string"},{"name":"nodeManagerPort","type":"int"},{"name":"nodeManagerHttpPort","type":"int"}]},{"type":"record","name":"JobPriorityChange","fields":[{"name":"jobid","type":"string"},{"name":"priority","type":"string"}]},{"type":"record","name":"JobQueueChange","fields":[{"name":"jobid","type":"string"},{"name":"jobQueueName","type":"string"}]},{"type":"record","name":"JobStatusChanged","fields":[{"name":"jobid","type":"string"},{"name":"jobStatus","type":"string"}]},{"type":"record","name":"JobSubmitted","fields":[{"name":"jobid","type":"string"},{"name":"jobName","type":"string"},{"name":"userName","type":"string"},{"name":"submitTime","type":"long"},{"name":"jobConfPath","type":"string"},{"name":"acls","type":{"type":"map","values":"string"}},{"name":"jobQueueName","type":"string"},{"name":"workflowId","type":["null","string"],"default":null},{"name":"workflowName","type":["null","string"],"default":null},{"name":"workflowNodeName","type":["null","string"],"default":null},{"name":"workflowAdjacencies","type":["null","string"],"default":null},{"name":"workflowTags","type":["null","string"],"default":null}]},{"type":"record","name":"JobUnsuccessfulCompletion","fields":[{"name":"jobid","type":"string"},{"name":"finishTime","type":"long"},{"name":"finishedMaps","type":"int"},{"name":"finishedReduces","type":"int"},{"name":"jobStatus","type":"string"},{"name":"diagnostics","type":["null","string"],"default":null},{"name":"failedMaps","type":"int","default":-1},{"name":"failedReduces","type":"int","default":-1},{"name":"killedMaps","type":"int","default":-1},{"name":"killedReduces","type":"int","default":-1}]},{"type":"record","name":"MapAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"mapFinishTime","type":"long"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"ReduceAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"shuffleFinishTime","type":"long"},{"name":"sortFinishTime","type":"long"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"TaskAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"finishTime","type":"long"},{"name":"rackname","type":"string"},{"name":"hostname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"}]},{"type":"record","name":"TaskAttemptStarted","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"attemptId","type":"string"},{"name":"startTime","type":"long"},{"name":"trackerName","type":"string"},{"name":"httpPort","type":"int"},{"name":"shufflePort","type":"int"},{"name":"containerId","type":"string"},{"name":"locality","type":["null","string"],"default":null},{"name":"avataar","type":["null","string"],"default":null}]},{"type":"record","name":"TaskAttemptUnsuccessfulCompletion","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"attemptId","type":"string"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"status","type":"string"},{"name":"error","type":"string"},{"name":"counters","type":["null","JhCounters"],"default":null},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"TaskFailed","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"finishTime","type":"long"},{"name":"error","type":"string"},{"name":"failedDueToAttempt","type":["null","string"]},{"name":"status","type":"string"},{"name":"counters","type":["null","JhCounters"],"default":null}]},{"type":"record","name":"TaskFinished","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"finishTime","type":"long"},{"name":"status","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"successfulAttemptId","type":["null","string"],"default":null}]},{"type":"record","name":"TaskStarted","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"startTime","type":"long"},{"name":"splitLocations","type":"string"}]},{"type":"record","name":"TaskUpdated","fields":[{"name":"taskid","type":"string"},{"name":"finishTime","type":"long"}]}]}]}
>Happattempt_1523887499615_0001_000001Î´ÚìÙXLcontainer_1523887499615_0001_01_000001anuragbdÖ¹Ô} ,job_1523887499615_0001word countnitzÐ÷ÓìÙX¼hdfs://192.168.0.104:9000/tmp/hadoop-yarn/staging/nitz/.staging/job_1523887499615_0001/job.xml default     

,job_1523887499615_0001default,job_1523887499615_0001þ ÛìÙXINITED ,job_1523887499615_0001Ð÷ÓìÙXþ ÛìÙX @task_1523887499615_0001_m_000000MAP¼¢ÛìÙX.anuragbd,jaiswalkautish @task_1523887499615_0001_r_000000REDUCEÊ¢ÛìÙX @task_1523887499615_0001_m_000000MAPJattempt_1523887499615_0001_m_000000_0ÀÈÛìÙXanuragbdÔ}ôÓLcontainer_1523887499615_0001_01_000002NODE_LOCALVIRGIN @task_1523887499615_0001_m_000000Jattempt_1523887499615_0001_m_000000_0MAPSUCCEEDEDè‘ÜìÙXÎœÜìÙXanuragbdÖ¹/default-rackmapCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes written¬ð'FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read† $HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework""MAP_INPUT_RECORDS"Map input recordsžB$MAP_OUTPUT_RECORDS$Map output recordsàÌ MAP_OUTPUT_BYTES Map output bytesæä,:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytes¤èSPLIT_RAW_BYTES"Input split bytesÔ*COMBINE_INPUT_RECORDS*Combine input recordsàÌ,COMBINE_OUTPUT_RECORDS,Combine output records¨‚SPILLED_RECORDSSpilled Records¨‚FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)Ú CPU_MILLISECONDS&CPU time spent (ms)!*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€Àþ¨(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€ÀèÛ(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€Àþ:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€é­8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àÿà xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read²ž  ¸Jppppppppppp àââàââàââàââ Ä’Ð·'ÜÜAæ\ò¦vüËˆñª’–Å »ßªàù´…”Âª® þÅüÑúÝøé
öõôòð™î¥ì±ê½ èÉ# @task_1523887499615_0001_m_000000MAPÎœÜìÙXSUCCEEDEDCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes written¬ð'FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read† $HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework""MAP_INPUT_RECORDS"Map input recordsžB$MAP_OUTPUT_RECORDS$Map output recordsàÌ MAP_OUTPUT_BYTES Map output bytesæä,:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytes¤èSPLIT_RAW_BYTES"Input split bytesÔ*COMBINE_INPUT_RECORDS*Combine input recordsàÌ,COMBINE_OUTPUT_RECORDS,Combine output records¨‚SPILLED_RECORDSSpilled Records¨‚FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)Ú CPU_MILLISECONDS&CPU time spent (ms)!*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€Àþ¨(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€ÀèÛ(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€Àþ:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€é­8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àÿà xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read²ž  Jattempt_1523887499615_0001_m_000000_0&@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_0ÎãÜìÙXjaiswalkautishÔ}Lcontainer_1523887499615_0001_01_000003OFF_SWITCHVIRGIN*@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_0ÐãÜìÙXjaiswalkautish®/default-rackFAILED°Container launch failed for container_1523887499615_0001_01_000003 : org.apache.hadoop.yarn.exceptions.YarnException: Unauthorized request to start container.
This token is expired. current time is 1523903701425 found 1523888424404
Note: System times on machines may be out of sync. Check system time and time zones.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
COUNTERS     &@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_1–§ÝìÙXjaiswalkautishÔ}Lcontainer_1523887499615_0001_01_000004OFF_SWITCHVIRGIN*@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_1˜§ÝìÙXjaiswalkautish®/default-rackFAILED°Container launch failed for container_1523887499615_0001_01_000004 : org.apache.hadoop.yarn.exceptions.YarnException: Unauthorized request to start container.
This token is expired. current time is 1523903705831 found 1523888429873
Note: System times on machines may be out of sync. Check system time and time zones.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
COUNTERS     &@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_2Š×ÝìÙXjaiswalkautishÔ}Lcontainer_1523887499615_0001_01_000005OFF_SWITCHVIRGIN*@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_2Š×ÝìÙXjaiswalkautish®/default-rackFAILED°Container launch failed for container_1523887499615_0001_01_000005 : org.apache.hadoop.yarn.exceptions.YarnException: Unauthorized request to start container.
This token is expired. current time is 1523903708897 found 1523888433024
Note: System times on machines may be out of sync. Check system time and time zones.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateExceptionImpl(SerializedExceptionPBImpl.java:171)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:182)
	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:163)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
COUNTERS     &@task_1523887499615_0001_r_000000REDUCEJattempt_1523887499615_0001_r_000000_3Š—ÞìÙXanuragbdÔ}ôÓLcontainer_1523887499615_0001_01_000006OFF_SWITCHVIRGIN(@task_1523887499615_0001_r_000000Jattempt_1523887499615_0001_r_000000_3REDUCESUCCEEDEDŒÖÞìÙXò×ÞìÙX²åÞìÙXanuragbdÖ¹/default-rackreduce > reduceCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read¤è$FILE_BYTES_WRITTEN:FILE: Number of bytes written¾ï'FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenˆæ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groups¨‚(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytes¤è(REDUCE_INPUT_RECORDS(Reduce input records¨‚*REDUCE_OUTPUT_RECORDS*Reduce output records¨‚SPILLED_RECORDSSpilled Records¨‚SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Þ CPU_MILLISECONDS&CPU time spent (ms)¬ *PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€À…Î(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€À£ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€—@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€À…Î>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€À£ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenˆæ
  €BŽŽŽŽŽŽŽŽ ØÚØÚØÚØÚØÚØÚ ìœÆÖ' BúÉ\Ôƒw®½‘ˆ÷«â°Æ¼êà–¤ûðÝ•Ê—° ®‰Šœæ®ÂÁ Ô	üæÚù´Œ’Ÿð±ÊÄ¨× @task_1523887499615_0001_r_000000REDUCE²åÞìÙXSUCCEEDEDCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read¤è$FILE_BYTES_WRITTEN:FILE: Number of bytes written¾ï'FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenˆæ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groups¨‚(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytes¤è(REDUCE_INPUT_RECORDS(Reduce input records¨‚*REDUCE_OUTPUT_RECORDS*Reduce output records¨‚SPILLED_RECORDSSpilled Records¨‚SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Þ CPU_MILLISECONDS&CPU time spent (ms)¬ *PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€À…Î(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€À£ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€—@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€À…Î>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€À£ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenˆæ
  Jattempt_1523887499615_0001_r_000000_3 ,job_1523887499615_0001úçÞìÙX  TOTAL_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read¤è$FILE_BYTES_WRITTEN:FILE: Number of bytes writtenêßOFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read† $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenˆæ
HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Lorg.apache.hadoop.mapreduce.JobCounterJob Counters $NUM_FAILED_REDUCES&Failed reduce tasks&TOTAL_LAUNCHED_MAPS$Launched map tasks,TOTAL_LAUNCHED_REDUCES*Launched reduce tasksDATA_LOCAL_MAPS(Data-local map tasks"SLOTS_MILLIS_MAPSfTotal time spent by all maps in occupied slots (ms)ŽT(SLOTS_MILLIS_REDUCESlTotal time spent by all reduces in occupied slots (ms)¬NMILLIS_MAPSLTotal time spent by all map tasks (ms)ŽTMILLIS_REDUCESRTotal time spent by all reduce tasks (ms)¬N$VCORES_MILLIS_MAPS^Total vcore-milliseconds taken by all map tasksŽT*VCORES_MILLIS_REDUCESdTotal vcore-milliseconds taken by all reduce tasks¬NMB_MILLIS_MAPSdTotal megabyte-milliseconds taken by all map tasks€ð "MB_MILLIS_REDUCESjTotal megabyte-milliseconds taken by all reduce tasks€àò Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework0"MAP_INPUT_RECORDS"Map input recordsžB$MAP_OUTPUT_RECORDS$Map output recordsàÌ MAP_OUTPUT_BYTES Map output bytesæä,:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytes¤èSPLIT_RAW_BYTES"Input split bytesÔ*COMBINE_INPUT_RECORDS*Combine input recordsàÌ,COMBINE_OUTPUT_RECORDS,Combine output records¨‚&REDUCE_INPUT_GROUPS&Reduce input groups¨‚(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytes¤è(REDUCE_INPUT_RECORDS(Reduce input records¨‚*REDUCE_OUTPUT_RECORDS*Reduce output records¨‚SPILLED_RECORDSSpilled RecordsÐ„SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)¸ CPU_MILLISECONDS&CPU time spent (ms)¼A*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€„÷(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€€ŒÇ'(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€À•:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€é­8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àÿà@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€À…Î>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€À£ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read²ž |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenˆæ
  MAP_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes written¬ð'FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read† $HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework""MAP_INPUT_RECORDS"Map input recordsžB$MAP_OUTPUT_RECORDS$Map output recordsàÌ MAP_OUTPUT_BYTES Map output bytesæä,:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytes¤èSPLIT_RAW_BYTES"Input split bytesÔ*COMBINE_INPUT_RECORDS*Combine input recordsàÌ,COMBINE_OUTPUT_RECORDS,Combine output records¨‚SPILLED_RECORDSSpilled Records¨‚FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)Ú CPU_MILLISECONDS&CPU time spent (ms)!*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€Àþ¨(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€ÀèÛ(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€Àþ:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€é­8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àÿà xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read²ž  REDUCE_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read¤è$FILE_BYTES_WRITTEN:FILE: Number of bytes written¾ï'FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenˆæ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groups¨‚(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytes¤è(REDUCE_INPUT_RECORDS(Reduce input records¨‚*REDUCE_OUTPUT_RECORDS*Reduce output records¨‚SPILLED_RECORDSSpilled Records¨‚SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Þ CPU_MILLISECONDS&CPU time spent (ms)¬ *PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€À…Î(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€À£ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€—@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€À…Î>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€À£ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenˆæ
    