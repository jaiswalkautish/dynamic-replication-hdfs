Avro-Binary
{"type":"record","name":"Event","namespace":"org.apache.hadoop.mapreduce.jobhistory","fields":[{"name":"type","type":{"type":"enum","name":"EventType","symbols":["JOB_SUBMITTED","JOB_INITED","JOB_FINISHED","JOB_PRIORITY_CHANGED","JOB_STATUS_CHANGED","JOB_QUEUE_CHANGED","JOB_FAILED","JOB_KILLED","JOB_ERROR","JOB_INFO_CHANGED","TASK_STARTED","TASK_FINISHED","TASK_FAILED","TASK_UPDATED","NORMALIZED_RESOURCE","MAP_ATTEMPT_STARTED","MAP_ATTEMPT_FINISHED","MAP_ATTEMPT_FAILED","MAP_ATTEMPT_KILLED","REDUCE_ATTEMPT_STARTED","REDUCE_ATTEMPT_FINISHED","REDUCE_ATTEMPT_FAILED","REDUCE_ATTEMPT_KILLED","SETUP_ATTEMPT_STARTED","SETUP_ATTEMPT_FINISHED","SETUP_ATTEMPT_FAILED","SETUP_ATTEMPT_KILLED","CLEANUP_ATTEMPT_STARTED","CLEANUP_ATTEMPT_FINISHED","CLEANUP_ATTEMPT_FAILED","CLEANUP_ATTEMPT_KILLED","AM_STARTED"]}},{"name":"event","type":[{"type":"record","name":"JobFinished","fields":[{"name":"jobid","type":"string"},{"name":"finishTime","type":"long"},{"name":"finishedMaps","type":"int"},{"name":"finishedReduces","type":"int"},{"name":"failedMaps","type":"int"},{"name":"failedReduces","type":"int"},{"name":"totalCounters","type":{"type":"record","name":"JhCounters","fields":[{"name":"name","type":"string"},{"name":"groups","type":{"type":"array","items":{"type":"record","name":"JhCounterGroup","fields":[{"name":"name","type":"string"},{"name":"displayName","type":"string"},{"name":"counts","type":{"type":"array","items":{"type":"record","name":"JhCounter","fields":[{"name":"name","type":"string"},{"name":"displayName","type":"string"},{"name":"value","type":"long"}]}}}]}}}]}},{"name":"mapCounters","type":"JhCounters"},{"name":"reduceCounters","type":"JhCounters"},{"name":"killedMaps","type":"int","default":-1},{"name":"killedReduces","type":"int","default":-1}]},{"type":"record","name":"JobInfoChange","fields":[{"name":"jobid","type":"string"},{"name":"submitTime","type":"long"},{"name":"launchTime","type":"long"}]},{"type":"record","name":"JobInited","fields":[{"name":"jobid","type":"string"},{"name":"launchTime","type":"long"},{"name":"totalMaps","type":"int"},{"name":"totalReduces","type":"int"},{"name":"jobStatus","type":"string"},{"name":"uberized","type":"boolean"}]},{"type":"record","name":"AMStarted","fields":[{"name":"applicationAttemptId","type":"string"},{"name":"startTime","type":"long"},{"name":"containerId","type":"string"},{"name":"nodeManagerHost","type":"string"},{"name":"nodeManagerPort","type":"int"},{"name":"nodeManagerHttpPort","type":"int"}]},{"type":"record","name":"JobPriorityChange","fields":[{"name":"jobid","type":"string"},{"name":"priority","type":"string"}]},{"type":"record","name":"JobQueueChange","fields":[{"name":"jobid","type":"string"},{"name":"jobQueueName","type":"string"}]},{"type":"record","name":"JobStatusChanged","fields":[{"name":"jobid","type":"string"},{"name":"jobStatus","type":"string"}]},{"type":"record","name":"JobSubmitted","fields":[{"name":"jobid","type":"string"},{"name":"jobName","type":"string"},{"name":"userName","type":"string"},{"name":"submitTime","type":"long"},{"name":"jobConfPath","type":"string"},{"name":"acls","type":{"type":"map","values":"string"}},{"name":"jobQueueName","type":"string"},{"name":"workflowId","type":["null","string"],"default":null},{"name":"workflowName","type":["null","string"],"default":null},{"name":"workflowNodeName","type":["null","string"],"default":null},{"name":"workflowAdjacencies","type":["null","string"],"default":null},{"name":"workflowTags","type":["null","string"],"default":null}]},{"type":"record","name":"JobUnsuccessfulCompletion","fields":[{"name":"jobid","type":"string"},{"name":"finishTime","type":"long"},{"name":"finishedMaps","type":"int"},{"name":"finishedReduces","type":"int"},{"name":"jobStatus","type":"string"},{"name":"diagnostics","type":["null","string"],"default":null},{"name":"failedMaps","type":"int","default":-1},{"name":"failedReduces","type":"int","default":-1},{"name":"killedMaps","type":"int","default":-1},{"name":"killedReduces","type":"int","default":-1}]},{"type":"record","name":"MapAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"mapFinishTime","type":"long"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"ReduceAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"shuffleFinishTime","type":"long"},{"name":"sortFinishTime","type":"long"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"TaskAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"finishTime","type":"long"},{"name":"rackname","type":"string"},{"name":"hostname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"}]},{"type":"record","name":"TaskAttemptStarted","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"attemptId","type":"string"},{"name":"startTime","type":"long"},{"name":"trackerName","type":"string"},{"name":"httpPort","type":"int"},{"name":"shufflePort","type":"int"},{"name":"containerId","type":"string"},{"name":"locality","type":["null","string"],"default":null},{"name":"avataar","type":["null","string"],"default":null}]},{"type":"record","name":"TaskAttemptUnsuccessfulCompletion","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"attemptId","type":"string"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"status","type":"string"},{"name":"error","type":"string"},{"name":"counters","type":["null","JhCounters"],"default":null},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"TaskFailed","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"finishTime","type":"long"},{"name":"error","type":"string"},{"name":"failedDueToAttempt","type":["null","string"]},{"name":"status","type":"string"},{"name":"counters","type":["null","JhCounters"],"default":null}]},{"type":"record","name":"TaskFinished","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"finishTime","type":"long"},{"name":"status","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"successfulAttemptId","type":["null","string"],"default":null}]},{"type":"record","name":"TaskStarted","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"startTime","type":"long"},{"name":"splitLocations","type":"string"}]},{"type":"record","name":"TaskUpdated","fields":[{"name":"taskid","type":"string"},{"name":"finishTime","type":"long"}]}]}]}
>Happattempt_1523650691711_0004_000001þ«®‹ØXLcontainer_1523650691711_0004_01_000001anuragbd”×Ô} ,job_1523650691711_0004wordCountjaiswalkautishŽÅ§‹ØXÐhdfs://192.168.0.104:9000/tmp/hadoop-yarn/staging/jaiswalkautish/.staging/job_1523650691711_0004/job.xml default     

,job_1523650691711_0004default,job_1523650691711_0004œÇ±‹ØXINITED ,job_1523650691711_0004ŽÅ§‹ØXœÇ±‹ØX @task_1523650691711_0004_m_000000MAPÀ…´‹ØX.jaiswalkautish,anuragbd @task_1523650691711_0004_r_000000REDUCEÐ…´‹ØX @task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_0´©´‹ØXjaiswalkautishÔ}Lcontainer_1523650691711_0004_01_000002NODE_LOCALVIRGIN"@task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_0º©´‹ØXjaiswalkautishŽˆ/default-rackFAILED°Container launch failed for container_1523650691711_0004_01_000002 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     @task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_1àÆ´‹ØXjaiswalkautishÔ}Lcontainer_1523650691711_0004_01_000003NODE_LOCALVIRGIN"@task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_1âÆ´‹ØXjaiswalkautishŽˆ/default-rackFAILED°Container launch failed for container_1523650691711_0004_01_000003 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     @task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_2¢æ´‹ØXjaiswalkautishÔ}Lcontainer_1523650691711_0004_01_000004NODE_LOCALVIRGIN"@task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_2¤æ´‹ØXjaiswalkautishŽˆ/default-rackFAILED°Container launch failed for container_1523650691711_0004_01_000004 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     @task_1523650691711_0004_m_000000MAPJattempt_1523650691711_0004_m_000000_3Ì‡µ‹ØXanuragbdÔ}ôÓLcontainer_1523650691711_0004_01_000005NODE_LOCALVIRGIN @task_1523650691711_0004_m_000000Jattempt_1523650691711_0004_m_000000_3MAPSUCCEEDEDÔè¶‹ØX®î¶‹ØXanuragbd”×/default-rackmapCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes writtenÎ˜FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes readÈ$HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework "MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records´ MAP_OUTPUT_BYTES Map output bytesš:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesŽSPLIT_RAW_BYTES"Input split bytesÄ*COMBINE_INPUT_RECORDS*Combine input records SPILLED_RECORDSSpilled Records´FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)Ì CPU_MILLISECONDS&CPU time spent (ms)˜*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€àš(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€Àêß(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€Â:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€àš8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àêß xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read„  Ôá<:<:<:<:<:< ‚‚‚‚‚‚‚‚‚‚‚‚ Æê	Ô¿â”1ðéDþ¾XŒ”lšé¨¾“¶“§ÄèºÒ½Îà’â À¼ÀµÀ®¾§
À ¾™À’¾‹À„Àý¾öÀï! @task_1523650691711_0004_m_000000MAP®î¶‹ØXSUCCEEDEDCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes writtenÎ˜FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes readÈ$HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework "MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records´ MAP_OUTPUT_BYTES Map output bytesš:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesŽSPLIT_RAW_BYTES"Input split bytesÄ*COMBINE_INPUT_RECORDS*Combine input records SPILLED_RECORDSSpilled Records´FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)Ì CPU_MILLISECONDS&CPU time spent (ms)˜*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€àš(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€Àêß(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€Â:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€àš8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àêß xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read„  Jattempt_1523650691711_0004_m_000000_3&@task_1523650691711_0004_r_000000REDUCEJattempt_1523650691711_0004_r_000000_0²–·‹ØXanuragbdÔ}ôÓLcontainer_1523650691711_0004_01_000006OFF_SWITCHVIRGIN(@task_1523650691711_0004_r_000000Jattempt_1523650691711_0004_r_000000_0REDUCESUCCEEDEDúê¸‹ØXØî¸‹ØXŠö¸‹ØXanuragbd”×/default-rackreduce > reduceCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readŽ$FILE_BYTES_WRITTEN:FILE: Number of bytes writtenà—FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenÄ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesŽ(REDUCE_INPUT_RECORDS(Reduce input records´*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled Records´SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Ê CPU_MILLISECONDS&CPU time spent (ms)¸*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€Ž¼(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€€™ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€t@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€€Ž¼>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€€™ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes WrittenÄ
  øØNNNNNNNNNNN ÄÄÆÄÄÆÄÄÆÄÄÆ ò	°ÖÒº1òžE”ƒY¶çlØË€ø¯”š”¨¼ø»ÜÜÏþÀã ²}œø„óêíÔèºã
¤ÞŠÙôÓÜÎÂÉ¬Ä @task_1523650691711_0004_r_000000REDUCEŠö¸‹ØXSUCCEEDEDCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readŽ$FILE_BYTES_WRITTEN:FILE: Number of bytes writtenà—FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenÄ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesŽ(REDUCE_INPUT_RECORDS(Reduce input records´*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled Records´SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Ê CPU_MILLISECONDS&CPU time spent (ms)¸*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€Ž¼(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€€™ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€t@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€€Ž¼>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€€™ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes WrittenÄ
  Jattempt_1523650691711_0004_r_000000_0 ,job_1523650691711_0004Ðø¸‹ØX  TOTAL_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readŽ$FILE_BYTES_WRITTEN:FILE: Number of bytes written®°2FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes readÈ$HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenÄ
HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Lorg.apache.hadoop.mapreduce.JobCounterJob Counters NUM_FAILED_MAPS Failed map tasks&TOTAL_LAUNCHED_MAPS$Launched map tasks,TOTAL_LAUNCHED_REDUCES*Launched reduce tasks OTHER_LOCAL_MAPS*Other local map tasksDATA_LOCAL_MAPS(Data-local map tasks"SLOTS_MILLIS_MAPSfTotal time spent by all maps in occupied slots (ms)à¶(SLOTS_MILLIS_REDUCESlTotal time spent by all reduces in occupied slots (ms)ÀýMILLIS_MAPSLTotal time spent by all map tasks (ms)ìæMILLIS_REDUCESRTotal time spent by all reduce tasks (ms)Øß$VCORES_MILLIS_MAPS^Total vcore-milliseconds taken by all map tasksìæ*VCORES_MILLIS_REDUCESdTotal vcore-milliseconds taken by all reduce tasksØßMB_MILLIS_MAPSdTotal megabyte-milliseconds taken by all map tasks€à¶"MB_MILLIS_REDUCESjTotal megabyte-milliseconds taken by all reduce tasks€Àý Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework0"MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records´ MAP_OUTPUT_BYTES Map output bytesš:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesŽSPLIT_RAW_BYTES"Input split bytesÄ*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesŽ(REDUCE_INPUT_RECORDS(Reduce input records´*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled RecordsèSHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)– CPU_MILLISECONDS&CPU time spent (ms)Ð*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€îÖ(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€ÀƒË(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€¶:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€àš8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àêß@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€€Ž¼>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€€™ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read„ |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes WrittenÄ
  MAP_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes writtenÎ˜FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes readÈ$HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework "MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records´ MAP_OUTPUT_BYTES Map output bytesš:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesŽSPLIT_RAW_BYTES"Input split bytesÄ*COMBINE_INPUT_RECORDS*Combine input records SPILLED_RECORDSSpilled Records´FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)Ì CPU_MILLISECONDS&CPU time spent (ms)˜*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€àš(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€Àêß(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€Â:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)€€àš8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)€Àêß xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes Read„  REDUCE_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readŽ$FILE_BYTES_WRITTEN:FILE: Number of bytes writtenà—FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenÄ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesŽ(REDUCE_INPUT_RECORDS(Reduce input records´*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled Records´SHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Ê CPU_MILLISECONDS&CPU time spent (ms)¸*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshot€€Ž¼(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshot€€™ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)€€€t@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)€€Ž¼>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)€€™ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes WrittenÄ
    