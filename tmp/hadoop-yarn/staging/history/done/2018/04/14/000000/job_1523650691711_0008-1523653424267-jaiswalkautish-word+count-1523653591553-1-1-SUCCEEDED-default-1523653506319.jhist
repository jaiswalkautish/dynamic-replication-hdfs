Avro-Binary
{"type":"record","name":"Event","namespace":"org.apache.hadoop.mapreduce.jobhistory","fields":[{"name":"type","type":{"type":"enum","name":"EventType","symbols":["JOB_SUBMITTED","JOB_INITED","JOB_FINISHED","JOB_PRIORITY_CHANGED","JOB_STATUS_CHANGED","JOB_QUEUE_CHANGED","JOB_FAILED","JOB_KILLED","JOB_ERROR","JOB_INFO_CHANGED","TASK_STARTED","TASK_FINISHED","TASK_FAILED","TASK_UPDATED","NORMALIZED_RESOURCE","MAP_ATTEMPT_STARTED","MAP_ATTEMPT_FINISHED","MAP_ATTEMPT_FAILED","MAP_ATTEMPT_KILLED","REDUCE_ATTEMPT_STARTED","REDUCE_ATTEMPT_FINISHED","REDUCE_ATTEMPT_FAILED","REDUCE_ATTEMPT_KILLED","SETUP_ATTEMPT_STARTED","SETUP_ATTEMPT_FINISHED","SETUP_ATTEMPT_FAILED","SETUP_ATTEMPT_KILLED","CLEANUP_ATTEMPT_STARTED","CLEANUP_ATTEMPT_FINISHED","CLEANUP_ATTEMPT_FAILED","CLEANUP_ATTEMPT_KILLED","AM_STARTED"]}},{"name":"event","type":[{"type":"record","name":"JobFinished","fields":[{"name":"jobid","type":"string"},{"name":"finishTime","type":"long"},{"name":"finishedMaps","type":"int"},{"name":"finishedReduces","type":"int"},{"name":"failedMaps","type":"int"},{"name":"failedReduces","type":"int"},{"name":"totalCounters","type":{"type":"record","name":"JhCounters","fields":[{"name":"name","type":"string"},{"name":"groups","type":{"type":"array","items":{"type":"record","name":"JhCounterGroup","fields":[{"name":"name","type":"string"},{"name":"displayName","type":"string"},{"name":"counts","type":{"type":"array","items":{"type":"record","name":"JhCounter","fields":[{"name":"name","type":"string"},{"name":"displayName","type":"string"},{"name":"value","type":"long"}]}}}]}}}]}},{"name":"mapCounters","type":"JhCounters"},{"name":"reduceCounters","type":"JhCounters"},{"name":"killedMaps","type":"int","default":-1},{"name":"killedReduces","type":"int","default":-1}]},{"type":"record","name":"JobInfoChange","fields":[{"name":"jobid","type":"string"},{"name":"submitTime","type":"long"},{"name":"launchTime","type":"long"}]},{"type":"record","name":"JobInited","fields":[{"name":"jobid","type":"string"},{"name":"launchTime","type":"long"},{"name":"totalMaps","type":"int"},{"name":"totalReduces","type":"int"},{"name":"jobStatus","type":"string"},{"name":"uberized","type":"boolean"}]},{"type":"record","name":"AMStarted","fields":[{"name":"applicationAttemptId","type":"string"},{"name":"startTime","type":"long"},{"name":"containerId","type":"string"},{"name":"nodeManagerHost","type":"string"},{"name":"nodeManagerPort","type":"int"},{"name":"nodeManagerHttpPort","type":"int"}]},{"type":"record","name":"JobPriorityChange","fields":[{"name":"jobid","type":"string"},{"name":"priority","type":"string"}]},{"type":"record","name":"JobQueueChange","fields":[{"name":"jobid","type":"string"},{"name":"jobQueueName","type":"string"}]},{"type":"record","name":"JobStatusChanged","fields":[{"name":"jobid","type":"string"},{"name":"jobStatus","type":"string"}]},{"type":"record","name":"JobSubmitted","fields":[{"name":"jobid","type":"string"},{"name":"jobName","type":"string"},{"name":"userName","type":"string"},{"name":"submitTime","type":"long"},{"name":"jobConfPath","type":"string"},{"name":"acls","type":{"type":"map","values":"string"}},{"name":"jobQueueName","type":"string"},{"name":"workflowId","type":["null","string"],"default":null},{"name":"workflowName","type":["null","string"],"default":null},{"name":"workflowNodeName","type":["null","string"],"default":null},{"name":"workflowAdjacencies","type":["null","string"],"default":null},{"name":"workflowTags","type":["null","string"],"default":null}]},{"type":"record","name":"JobUnsuccessfulCompletion","fields":[{"name":"jobid","type":"string"},{"name":"finishTime","type":"long"},{"name":"finishedMaps","type":"int"},{"name":"finishedReduces","type":"int"},{"name":"jobStatus","type":"string"},{"name":"diagnostics","type":["null","string"],"default":null},{"name":"failedMaps","type":"int","default":-1},{"name":"failedReduces","type":"int","default":-1},{"name":"killedMaps","type":"int","default":-1},{"name":"killedReduces","type":"int","default":-1}]},{"type":"record","name":"MapAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"mapFinishTime","type":"long"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"ReduceAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"shuffleFinishTime","type":"long"},{"name":"sortFinishTime","type":"long"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"TaskAttemptFinished","fields":[{"name":"taskid","type":"string"},{"name":"attemptId","type":"string"},{"name":"taskType","type":"string"},{"name":"taskStatus","type":"string"},{"name":"finishTime","type":"long"},{"name":"rackname","type":"string"},{"name":"hostname","type":"string"},{"name":"state","type":"string"},{"name":"counters","type":"JhCounters"}]},{"type":"record","name":"TaskAttemptStarted","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"attemptId","type":"string"},{"name":"startTime","type":"long"},{"name":"trackerName","type":"string"},{"name":"httpPort","type":"int"},{"name":"shufflePort","type":"int"},{"name":"containerId","type":"string"},{"name":"locality","type":["null","string"],"default":null},{"name":"avataar","type":["null","string"],"default":null}]},{"type":"record","name":"TaskAttemptUnsuccessfulCompletion","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"attemptId","type":"string"},{"name":"finishTime","type":"long"},{"name":"hostname","type":"string"},{"name":"port","type":"int"},{"name":"rackname","type":"string"},{"name":"status","type":"string"},{"name":"error","type":"string"},{"name":"counters","type":["null","JhCounters"],"default":null},{"name":"clockSplits","type":{"type":"array","items":"int"}},{"name":"cpuUsages","type":{"type":"array","items":"int"}},{"name":"vMemKbytes","type":{"type":"array","items":"int"}},{"name":"physMemKbytes","type":{"type":"array","items":"int"}}]},{"type":"record","name":"TaskFailed","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"finishTime","type":"long"},{"name":"error","type":"string"},{"name":"failedDueToAttempt","type":["null","string"]},{"name":"status","type":"string"},{"name":"counters","type":["null","JhCounters"],"default":null}]},{"type":"record","name":"TaskFinished","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"finishTime","type":"long"},{"name":"status","type":"string"},{"name":"counters","type":"JhCounters"},{"name":"successfulAttemptId","type":["null","string"],"default":null}]},{"type":"record","name":"TaskStarted","fields":[{"name":"taskid","type":"string"},{"name":"taskType","type":"string"},{"name":"startTime","type":"long"},{"name":"splitLocations","type":"string"}]},{"type":"record","name":"TaskUpdated","fields":[{"name":"taskid","type":"string"},{"name":"finishTime","type":"long"}]}]}]}
>Happattempt_1523650691711_0008_000002¥≥òçÿXLcontainer_1523650691711_0008_02_000001anuragbdî◊‘} ,job_1523650691711_0008word countjaiswalkautishñ“ëçÿX–hdfs://192.168.0.104:9000/tmp/hadoop-yarn/staging/jaiswalkautish/.staging/job_1523650691711_0008/job.xml default     

,job_1523650691711_0008default,job_1523650691711_0008û‘õçÿXINITED ,job_1523650691711_0008ñ“ëçÿXû‘õçÿX @task_1523650691711_0008_m_000000MAPöíûçÿX.jaiswalkautish,anuragbd @task_1523650691711_0008_r_000000REDUCEÆíûçÿX @task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1000‡∏ûçÿXjaiswalkautish‘}Lcontainer_1523650691711_0008_02_000002NODE_LOCALVIRGIN"@task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1000Ë∏ûçÿXjaiswalkautishéà/default-rackFAILED∞Container launch failed for container_1523650691711_0008_02_000002 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     @task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1001æ’ûçÿXjaiswalkautish‘}Lcontainer_1523650691711_0008_02_000003NODE_LOCALVIRGIN"@task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1001æ’ûçÿXjaiswalkautishéà/default-rackFAILED∞Container launch failed for container_1523650691711_0008_02_000003 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     @task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1002åıûçÿXjaiswalkautish‘}Lcontainer_1523650691711_0008_02_000004NODE_LOCALVIRGIN"@task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1002åıûçÿXjaiswalkautishéà/default-rackFAILED∞Container launch failed for container_1523650691711_0008_02_000004 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     @task_1523650691711_0008_m_000000MAPPattempt_1523650691711_0008_m_000000_1003òñüçÿXanuragbd‘}Ù”Lcontainer_1523650691711_0008_02_000005NODE_LOCALVIRGIN @task_1523650691711_0008_m_000000Pattempt_1523650691711_0008_m_000000_1003MAPSUCCEEDED¢˜†çÿXŒ˙†çÿXanuragbdî◊/default-rackmapCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes written®îFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read»$HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework""MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records¥ MAP_OUTPUT_BYTES Map output bytesö:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesÆSPLIT_RAW_BYTES"Input split bytesƒ*COMBINE_INPUT_RECORDS*Combine input records¥,COMBINE_OUTPUT_RECORDS,Combine output recordsxSPILLED_RECORDSSpilled RecordsxFAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)æ CPU_MILLISECONDS&CPU time spent (ms)‡*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄ˙°(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄ¿ê·(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄÄ¬:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)ÄÄ˙°8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)Ä¿ê· xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes ReadÑ  ∫·""""" """"" ííîííîííîííî ¥Î	û¬åô1ˆÔD‚∆XÃùl∏Ù¢Àìê¢ß˙¯∫‰œŒ“¶‚ §¡Ú√¿∆å…
⁄À®Œˆ–¬”ê÷ﬁÿ™€¯›" @task_1523650691711_0008_m_000000MAPŒ˙†çÿXSUCCEEDEDCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes written®îFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read»$HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework""MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records¥ MAP_OUTPUT_BYTES Map output bytesö:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesÆSPLIT_RAW_BYTES"Input split bytesƒ*COMBINE_INPUT_RECORDS*Combine input records¥,COMBINE_OUTPUT_RECORDS,Combine output recordsxSPILLED_RECORDSSpilled RecordsxFAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)æ CPU_MILLISECONDS&CPU time spent (ms)‡*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄ˙°(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄ¿ê·(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄÄ¬:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)ÄÄ˙°8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)Ä¿ê· xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes ReadÑ  Pattempt_1523650691711_0008_m_000000_1003&@task_1523650691711_0008_r_000000REDUCEPattempt_1523650691711_0008_r_000000_1000Ä‰£çÿXjaiswalkautish‘}Lcontainer_1523650691711_0008_02_000006OFF_SWITCHVIRGIN*@task_1523650691711_0008_r_000000REDUCEPattempt_1523650691711_0008_r_000000_1000Ç‰£çÿXjaiswalkautishéà/default-rackFAILED∞Container launch failed for container_1523650691711_0008_02_000006 : java.lang.IllegalArgumentException: java.net.UnknownHostException: jaiswalkautish
	at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:444)
	at org.apache.hadoop.security.SecurityUtil.setTokenService(SecurityUtil.java:422)
	at org.apache.hadoop.yarn.util.ConverterUtils.convertFromYarn(ConverterUtils.java:184)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:277)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:252)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:137)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:433)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: jaiswalkautish
	... 12 more
COUNTERS     &@task_1523650691711_0008_r_000000REDUCEPattempt_1523650691711_0008_r_000000_1001Ñü§çÿXanuragbd‘}Ù”Lcontainer_1523650691711_0008_02_000007OFF_SWITCHVIRGIN(@task_1523650691711_0008_r_000000Pattempt_1523650691711_0008_r_000000_1001REDUCESUCCEEDED˙ı•çÿX˛˜•çÿX∫Ü¶çÿXanuragbdî◊/default-rackreduce > reduceCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readÆ$FILE_BYTES_WRITTEN:FILE: Number of bytes written∫ìFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenƒ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesÆ(REDUCE_INPUT_RECORDS(Reduce input recordsx*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled RecordsxSHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Ó CPU_MILLISECONDS&CPU time spent (ms)ê*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄÇæ(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄ¿∑Ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄ¿u@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)ÄÄÇæ>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)Ä¿∑Ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenƒ
  †⁄òòöòòòöòòòö ˆˆ¯ˆˆ¯ˆˆ¯ˆˆ¯ §	Ó–∏±1ÇíEÃÚXñ”l‡≥Ä™îîÙÙßæ’ªà∂œ“ñ„ ‘~Ç¸∞˘‹ˆäÙ∏Ò
ÊÓíÏ¿ÈÓÊö‰»· @task_1523650691711_0008_r_000000REDUCE∫Ü¶çÿXSUCCEEDEDCOUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readÆ$FILE_BYTES_WRITTEN:FILE: Number of bytes written∫ìFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenƒ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesÆ(REDUCE_INPUT_RECORDS(Reduce input recordsx*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled RecordsxSHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Ó CPU_MILLISECONDS&CPU time spent (ms)ê*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄÇæ(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄ¿∑Ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄ¿u@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)ÄÄÇæ>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)Ä¿∑Ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenƒ
  Pattempt_1523650691711_0008_r_000000_1001 ,job_1523650691711_0008Çà¶çÿX  TOTAL_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readÆ$FILE_BYTES_WRITTEN:FILE: Number of bytes written‚ß2FILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read»$HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenƒ
HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Lorg.apache.hadoop.mapreduce.JobCounterJob Counters NUM_FAILED_MAPS Failed map tasks$NUM_FAILED_REDUCES&Failed reduce tasks&TOTAL_LAUNCHED_MAPS$Launched map tasks,TOTAL_LAUNCHED_REDUCES*Launched reduce tasks OTHER_LOCAL_MAPS*Other local map tasksDATA_LOCAL_MAPS(Data-local map tasks"SLOTS_MILLIS_MAPSfTotal time spent by all maps in occupied slots (ms)£(SLOTS_MILLIS_REDUCESlTotal time spent by all reduces in occupied slots (ms)¿ªMILLIS_MAPSLTotal time spent by all map tasks (ms)æ‰MILLIS_REDUCESRTotal time spent by all reduce tasks (ms)∏Á$VCORES_MILLIS_MAPS^Total vcore-milliseconds taken by all map tasksæ‰*VCORES_MILLIS_REDUCESdTotal vcore-milliseconds taken by all reduce tasks∏ÁMB_MILLIS_MAPSdTotal megabyte-milliseconds taken by all map tasksÄ£"MB_MILLIS_REDUCESjTotal megabyte-milliseconds taken by all reduce tasksÄ¿ª Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework0"MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records¥ MAP_OUTPUT_BYTES Map output bytesö:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesÆSPLIT_RAW_BYTES"Input split bytesƒ*COMBINE_INPUT_RECORDS*Combine input records¥,COMBINE_OUTPUT_RECORDS,Combine output recordsx&REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesÆ(REDUCE_INPUT_RECORDS(Reduce input recordsx*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled RecordsSHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)¨ CPU_MILLISECONDS&CPU time spent (ms)$*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄ¸ﬂ(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄÄ»…(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄ¿∑:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)ÄÄ˙°8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)Ä¿ê·@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)ÄÄÇæ>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)Ä¿∑Ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes ReadÑ |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenƒ
  MAP_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes read $FILE_BYTES_WRITTEN:FILE: Number of bytes written®îFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read»$HDFS_BYTES_WRITTEN:HDFS: Number of bytes written HDFS_READ_OPS>HDFS: Number of read operations&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations  Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework""MAP_INPUT_RECORDS"Map input records:$MAP_OUTPUT_RECORDS$Map output records¥ MAP_OUTPUT_BYTES Map output bytesö:MAP_OUTPUT_MATERIALIZED_BYTES:Map output materialized bytesÆSPLIT_RAW_BYTES"Input split bytesƒ*COMBINE_INPUT_RECORDS*Combine input records¥,COMBINE_OUTPUT_RECORDS,Combine output recordsxSPILLED_RECORDSSpilled RecordsxFAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputs GC_TIME_MILLIS(GC time elapsed (ms)æ CPU_MILLISECONDS&CPU time spent (ms)‡*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄ˙°(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄ¿ê·(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄÄ¬:MAP_PHYSICAL_MEMORY_BYTES_MAX@Peak Map Physical memory (bytes)ÄÄ˙°8MAP_VIRTUAL_MEMORY_BYTES_MAX>Peak Map Virtual memory (bytes)Ä¿ê· xorg.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter6File Input Format Counters BYTES_READBytes ReadÑ  REDUCE_COUNTERSZorg.apache.hadoop.mapreduce.FileSystemCounter(File System CountersFILE_BYTES_READ4FILE: Number of bytes readÆ$FILE_BYTES_WRITTEN:FILE: Number of bytes written∫ìFILE_READ_OPS>FILE: Number of read operations &FILE_LARGE_READ_OPSJFILE: Number of large read operations FILE_WRITE_OPS@FILE: Number of write operations HDFS_BYTES_READ4HDFS: Number of bytes read $HDFS_BYTES_WRITTEN:HDFS: Number of bytes writtenƒ
HDFS_READ_OPS>HDFS: Number of read operations
&HDFS_LARGE_READ_OPSJHDFS: Number of large read operations HDFS_WRITE_OPS@HDFS: Number of write operations Norg.apache.hadoop.mapreduce.TaskCounter(Map-Reduce Framework"*COMBINE_INPUT_RECORDS*Combine input records ,COMBINE_OUTPUT_RECORDS,Combine output records &REDUCE_INPUT_GROUPS&Reduce input groupsx(REDUCE_SHUFFLE_BYTES(Reduce shuffle bytesÆ(REDUCE_INPUT_RECORDS(Reduce input recordsx*REDUCE_OUTPUT_RECORDS*Reduce output recordsxSPILLED_RECORDSSpilled RecordsxSHUFFLED_MAPSShuffled Maps FAILED_SHUFFLEFailed Shuffles $MERGED_MAP_OUTPUTS$Merged Map outputsGC_TIME_MILLIS(GC time elapsed (ms)Ó CPU_MILLISECONDS&CPU time spent (ms)ê*PHYSICAL_MEMORY_BYTES@Physical memory (bytes) snapshotÄÄÇæ(VIRTUAL_MEMORY_BYTES>Virtual memory (bytes) snapshotÄ¿∑Ë(COMMITTED_HEAP_BYTESDTotal committed heap usage (bytes)ÄÄ¿u@REDUCE_PHYSICAL_MEMORY_BYTES_MAXFPeak Reduce Physical memory (bytes)ÄÄÇæ>REDUCE_VIRTUAL_MEMORY_BYTES_MAXDPeak Reduce Virtual memory (bytes)Ä¿∑Ë Shuffle ErrorsShuffle ErrorsBAD_IDBAD_ID CONNECTIONCONNECTION IO_ERRORIO_ERROR WRONG_LENGTHWRONG_LENGTH WRONG_MAPWRONG_MAP WRONG_REDUCEWRONG_REDUCE  |org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter8File Output Format Counters BYTES_WRITTENBytes Writtenƒ
    